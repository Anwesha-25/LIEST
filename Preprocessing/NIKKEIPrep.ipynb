{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d915afeb",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0b5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131cdce0",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a449f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the csv files\n",
    "dataname = 'NIKKEI'\n",
    "dir = 'D:/Research/LIEST/Data/'\n",
    "csv_files = glob.glob(dir+'RawData/NIKKEI/*.csv')\n",
    "\n",
    "# List comprehension that loads of all the files\n",
    "dfs = [pd.read_csv(i) for i in csv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48cb6bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = []\n",
    "for i in range(len(csv_files)):\n",
    "    base = os.path.basename(os.path.normpath(csv_files[i]))\n",
    "    path.append(os.path.splitext(base)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7cf84c",
   "metadata": {},
   "source": [
    "# Company-Sector tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9dd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Technology = ['6706.T', '6817.T', '6810.T', '4427.T', '4425.T', '6836.T', '3803.T', '2323.T', '6977.T', '3913.T', '9425.T', '4444.T',\n",
    "              '4335.T', '6942.T',  '6550.T']\n",
    "\n",
    "Healthcare = ['4563.T', '6190.T', '4583.T', '4586.T', '4570.T', '6090.T', '4584.T', '4556.T', '7681.T', '4355.T', '6545.T','6029.T',\n",
    "              '7813.T', '7037.T']\n",
    "\n",
    "Consumer_cyclical = ['7683.T', '7682.T', '2753.T', '2752.T', '6191.T','8181.T', '3358.T', '3953.T','3571.T']\n",
    "\n",
    "Consumer_Defensive = ['1333.T','1382.T', '2901.T', '2926.T', '5341.T', '4918.T', '7073.T', '4920.T','7515.T', '2683.T','2107.T', \n",
    "                      '2112.T', '7413.T']\n",
    "\n",
    "Utilities = ['2743.T', '1711.T', '9514.T', '9517.T', '9513.T', '9511.T', '9519.T', '9532.T', '9531.T', '9533.T']\n",
    "\n",
    "Energy = ['7462.T', '5010.T', '5009.T', '7486.T', '9386.T', '5015.T', '5019.T', '5017.T', '5020.T', '5021.T']\n",
    "\n",
    "Basic_material = ['3103.T', '5707.T', '5541.T','3101.T', '5486.T', '5632.T', '3945.T', '3892.T', '1971.T']\n",
    "\n",
    "Industrial = ['7004.T', '6472.T', '6103.T', '5932.T','6440.T', '4657.T','1716.T', '6403.T','4651.T', '2749.T', '7314.T',\n",
    "              '7018.T', '5603.T']\n",
    "\n",
    "Financial = ['8558.T', '8624.T', '2134.T', '8742.T', '7162.T', '8746.T', '8617.T', '7175.T', '8518.T', '8747.T', '9318.T',\n",
    "             '6196.T', '8783.T', '8789.T', '7192.T', '6178.T']\n",
    "\n",
    "Communication = ['2440.T', '4760.T', '8072.T', '6177.T', '2459.T', '3929.T', '3137.T', '6026.T', '3842.T']\n",
    "\n",
    "Automobile = ['5202.T','7294.T', '7623.T', '5104.T', '5101.T', '5105.T', '5108.T', '2754.T','7255.T', '7259.T', '7256.T', '7254.T', \n",
    "              '7273.T', '5162.T']\n",
    "\n",
    "Real_Estate = [ '6192.T', '8905.T', '8908.T', '8995.T', '1400.T', '3261.T', '3494.T', '7837.T']\n",
    "\n",
    "sector = [Technology, Healthcare, Consumer_cyclical, Consumer_Defensive, Utilities, Energy,\n",
    "          Basic_material, Industrial, Financial, Communication, Automobile, Real_Estate]\n",
    "\n",
    "sectorname = ['Technology', 'Healthcare', 'Consumer_cyclical', 'Consumer_Defensive', 'Utilities', 'Energy',\n",
    "              'Basic_material', 'Industrial', 'Financial', 'Communication', 'Automobile', 'Real_Estate']\n",
    "\n",
    "sectordict = {sectorname[i]: sector[i] for i in range(len(sector))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd0efc",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc52157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing indices of each dataframe\n",
    "for i in range(len(csv_files)):\n",
    "    dfs[i].set_index(\"Date\", inplace = True)\n",
    "    dfs[i].index= pd.to_datetime(dfs[i].index)\n",
    "    dfs[i].index = dfs[i].index.strftime('%Y-%m-%d')\n",
    "\n",
    "#Considering Closing price for each stock\n",
    "dfs_copy = [pd.DataFrame(dfs[i].loc[:,'Close']) for i in range(len(csv_files))]\n",
    "\n",
    "# Merging all parts (Stock name as column name and date as index)\n",
    "dfs_main = pd.concat(dfs_copy , axis = 1) \n",
    "dfs_main = dfs_main.set_axis(path , axis=1)\n",
    "dfs_main = dfs_main.sort_index()\n",
    "\n",
    "# dfs main (filling nan values by previous values)\n",
    "dfs_main.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a784f",
   "metadata": {},
   "source": [
    "# Saving the preprocessed data and company sector labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebc21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In covid data\n",
    "dfs_main.loc['2019-12-01':'2020-08-31',:].to_csv(dir+'PreprocessedData/'+dataname+'_in_covid.csv')\n",
    "# post covid data\n",
    "dfs_main.loc['2020-09-01':'2021-06-31',:].to_csv(dir+'PreprocessedData/'+dataname+'_post_covid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1031e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving csLabels\n",
    "with open(dir+\"CSLabels/\"+dataname+\"Sectors.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(sectordict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c221c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Company names\n",
    "with open(dir+\"CSLabels/\"+dataname+\"Companies.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(path, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
