{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d915afeb",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0b5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131cdce0",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a449f239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the csv files\n",
    "dataname = 'UK_STOCK'\n",
    "dir = 'D:/Research/LIEST/Data/'\n",
    "csv_files = glob.glob(dir+'RawData/UK_STOCK/*.csv')\n",
    "\n",
    "# List comprehension that loads of all the files\n",
    "dfs = [pd.read_csv(i) for i in csv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48cb6bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = []\n",
    "for i in range(len(csv_files)):\n",
    "    base = os.path.basename(os.path.normpath(csv_files[i]))\n",
    "    path.append(os.path.splitext(base)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7cf84c",
   "metadata": {},
   "source": [
    "# Company-Sector tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9dd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CC = ['AO.L', 'CARD.L', 'FSTA.L', 'HFD.L', 'GYM.L','HEAD.L','BOWL.L','CPG.L','CCL.L','FRAS.L','HWDN.L','TW.L','PSN.L',\n",
    "      'BDEV.L','BKG.L','SMDS.L','WTB.L', 'COA.L']\n",
    "\n",
    "CD = ['AEP.L', 'GNC.L','ULVR.L','DGE.L','BATS.L','RKT.L','TSCO.L','ABF.L', 'BNZL.L','SBRY.L','PZC.L','PFD.L']\n",
    "\n",
    "Financial = ['ADIG.L', 'ANII.L','ASIT.L','AAIF.L','ACIC.L','ASLI.L', 'AUSC.L', 'ATS.L', 'AIE.L','DGN.L',\n",
    "             'AUGM.L','BGCG.L','BGS.L', 'CSN.L', 'FCH.L', 'HSBA.L','LSEG.L','PRU.L','LLOY.L', 'BARC.L',\n",
    "             'NWG.L','III.L','ABDN.L','LIO.L']\n",
    "\n",
    "Automobile = ['ABDP.L', 'TIFS.L', 'AML.L', 'SCE.L', 'TRT.L', 'AUTG.L']\n",
    "\n",
    "Real_estate = ['AEWU.L', 'BOOT.L','HWG.L','HLCL.L','IHR.L', 'MLI.L','SHED.L','HMSO.L','THRL.L']\n",
    "\n",
    "Technology = ['ALFA.L', 'APTD.L', 'AVV.L',  'SXS.L','OXIG.L']\n",
    "\n",
    "HC = ['AZN.L','GSK.L','SN.L', 'MDC.L','HIK.L','CTEC.L','GDR.L', 'YGEN.L', 'NCYT.L','MXCT.L', 'RENX.L']\n",
    "\n",
    "Industrial = ['AVON.L', 'DLAR.L', 'HYVE.L','EXPN.L', 'BA.L','RTO.L','DPLM.L','IMI.L','RS1.L','WEIR.L',\n",
    "              'SMIN.L', 'SPX.L','BOY.L' ]\n",
    "\n",
    "Communication = ['BMY.L', 'REL.L','WPP.L','ITV.L', 'AAF.L','AUTO.L','RMV.L']\n",
    "\n",
    "BM = ['FORT.L','HOC.L', 'RIO.L','GLEN.L','AAL.L','ANTO.L','CRDA.L','JMAT.L']\n",
    "\n",
    "Energy = ['HTG.L','SHEL.L','BP.L','POS.L', 'WTE.L', 'TOM.L']\n",
    "\n",
    "Utilities = ['NG.L','SSE.L','CNA.L']\n",
    "\n",
    "sector = [CC, CD, Financial, Automobile, Real_estate, Technology, HC, Industrial,\n",
    "          Communication, BM, Energy, Utilities ]\n",
    "\n",
    "sectorname = ['CC', 'CD', 'Financial', 'Automobile', 'Real_estate', 'Technology',\n",
    "              'HC', 'Industrial', 'Communication', 'BM', 'Energy', 'Utilities']\n",
    "\n",
    "sectordict = {sectorname[i]: sector[i] for i in range(len(sector))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd0efc",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc52157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing indices of each dataframe\n",
    "for i in range(len(csv_files)):\n",
    "    dfs[i].set_index(\"Date\", inplace = True)\n",
    "    dfs[i].index= pd.to_datetime(dfs[i].index)\n",
    "    dfs[i].index = dfs[i].index.strftime('%Y-%m-%d')\n",
    "\n",
    "#Considering Closing price for each stock\n",
    "dfs_copy = [pd.DataFrame(dfs[i].loc[:,'Close']) for i in range(len(csv_files))]\n",
    "\n",
    "# Merging all parts (Stock name as column name and date as index)\n",
    "dfs_main = pd.concat(dfs_copy , axis = 1) \n",
    "dfs_main = dfs_main.set_axis(path , axis=1)\n",
    "dfs_main = dfs_main.sort_index()\n",
    "\n",
    "# dfs main (filling nan values by previous values)\n",
    "dfs_main.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a784f",
   "metadata": {},
   "source": [
    "# Saving the preprocessed data and company sector labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ebc21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In covid data\n",
    "dfs_main.loc['2019-12-01':'2020-08-31',:].to_csv(dir+'PreprocessedData/'+dataname+'_in_covid.csv')\n",
    "# post covid data\n",
    "dfs_main.loc['2020-09-01':'2021-06-31',:].to_csv(dir+'PreprocessedData/'+dataname+'_post_covid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1031e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving csLabels\n",
    "with open(dir+\"CSLabels/\"+dataname+\"Sectors.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(sectordict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c221c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Company names\n",
    "with open(dir+\"CSLabels/\"+dataname+\"Companies.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(path, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
